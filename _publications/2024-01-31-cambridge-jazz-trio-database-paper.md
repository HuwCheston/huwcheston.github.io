---
title: "Cambridge Jazz Trio Database: Automated Timing Annotation of Jazz Piano Trio Recordings Processed Using Audio Source Separation"
collection: publications
preprint: true
excerpt: 'We introduce the Cambridge Jazz Trio Database, a dataset of 12 hours of jazz piano trio recordings with automatically generated timing annotations for every performer (piano soloist, bass and drums accompaniment) in the ensemble.'
date: 2024-01-31
venue: 'PsyArXiv'
paperurl: 'https://doi.org/10.31234/osf.io/jyqp3'
imgurl: '/images/trio-database_img.png'
citation: 'Cheston, H., Schlichting, J. S., Cross, I., & Harrison, P. M. C. (2024). &quot;Cambridge Jazz Trio
Database: Automated Timing Annotation of Jazz Piano Trio Recordings Processed Using Audio
Source Separation.&quot; <i>PsyArXiv</i>.'
---

<img src='/images/trio-database-explorer_img.png'>

[![Preprint](http://img.shields.io/badge/Preprint-DOI:_10.31234/osf.io/jyqp3-blue)](https://doi.org/10.31234/osf.io/jyqp3) <br>
[![Code](http://img.shields.io/badge/Code-available_on_GitHub-purple)](https://github.com/HuwCheston/Cambridge-Jazz-Trio-Database) [![Documentation](http://img.shields.io/badge/Documentation-available_on_GitHub-purple)](https://huwcheston.github.io/Cambridge-Jazz-Trio-Database/)

Recent advances in automatic music transcription have facilitated the creation of large databases of improvised music forms (including jazz), where traditional notated scores are typically not available. However, most of these datasets focus only on capturing the improvisations of soloists, omitting the contributions of the accompanying members in an ensemble to a performance. We introduce the Cambridge Jazz Trio Database, a dataset of 12 hours of jazz piano trio recordings with automatically generated timing annotations for every performer (piano soloist, bass and drums accompaniment) in the ensemble. Appropriate recordings are identified by scraping user-based listening and discographic data, source separation models are applied to isolate audio for each performer in the piano trio, and timing annotations are generated by applying beat and onset detection algorithms to the separated audio sources. We conduct several analyses of the dataset, including with relation to swing and inter-performer synchronization. We anticipate the dataset will be useful in a variety of music information retrieval tasks, including performer identification and symbolic music generation. The database, including the source code and related documentation, is available at https://github.com/huwcheston/Cambridge-Jazz-Trio-Database. 