---
title: "Rhythmic Qualities of Jazz Improvisation Predict Performer Identity and Style in Source-Separated Audio Recordings."
collection: publications
preprint: false
excerpt: 'We demonstrate that a supervised learning model trained solely on rhythmic features extracted from 300 source-separated audio recordings of jazz pianists was capable of identifying the performer in 52% of cases, over five times better than chance.'
date: 2024-01-31
venue: 'Royal Society Open Science'
paperurl: 'https://doi.org/10.31234/osf.io/txy2f'
imgurl: '/images/pianist-prediction_img.png'
citation: 'Cheston, H., Schlichting, J. S., Cross, I., & Harrison, P. M. C. Rhythmic Qualities of Jazz Improvisation Predict Performer Identity and Style in Source-Separated Audio Recordings. <i>Royal Society Open Science</i>. 2024 (accepted, subject to minor revisions)'
---

<img src='/images/pianist-prediction_img.png'>

[![Preprint](http://img.shields.io/badge/Preprint-DOI:_10.31234/osf.io/txy2f-blue)](https://doi.org/10.31234/osf.io/txy2f) <br>
[![Code](http://img.shields.io/badge/Code-available_on_GitHub-purple)](https://github.com/HuwCheston/Cambridge-Jazz-Trio-Database) [![Documentation](http://img.shields.io/badge/Documentation-available_on_GitHub-purple)](https://huwcheston.github.io/Cambridge-Jazz-Trio-Database/)

Great musicians have a unique style and, with training, humans can learn to distinguish between these styles. Designing a computational model that can accomplish this task is a challenge in music information retrieval research, as it may require us to think about the areas in which two performers are likely to differ. One possibility is that musicians may vary in terms of their use of rhythm – which, unlike harmony, melody, or timbre, has relevance to any instrument. We demonstrate that a supervised learning  model trained solely on rhythmic features extracted from 300 recordings of ten jazz pianists correctly identified the performer in 59% of cases, six times better than chance. The most important features related to a performer’s “feel” (ensemble synchronization), “complexity” (information density), and “swing” (characteristic subdivision of the musical pulse). Further analysis revealed two clusters of performers, with those in the same cluster demonstrating similar rhythmic traits. Our findings highlight the possibility that artificial intelligence can perform performer identification tasks normally reserved for experts. Links to each recording and the corresponding predictions are available [on an interactive map](https://huwcheston.github.io/Jazz-Trio-Database/_static/prediction-app.html) to support future work in stylometry.
